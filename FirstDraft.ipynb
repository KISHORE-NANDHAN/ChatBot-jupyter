{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a98f65c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install pymongo python-dotenv transformers torch fuzzywuzzy spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aecbba32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84107792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6a0717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_huba\n",
    "# !pip install transformers\n",
    "# !pip install accelerate\n",
    "# !pip install  bitsandbytes\n",
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abea1be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (2.10.6)\n",
      "Requirement already satisfied: langchain in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-core in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (0.3.40)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: anyio in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\users\\kishore nandhan\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pydantic langchain langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac10d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import spacy\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://Admin:Manager@cluster0.vths3.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "db = client[\"CollegeDB\"]\n",
    "faculty_collection = db[\"departments\"]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "#  Check if the collection exists by counting documents\n",
    "# if faculty_collection.estimated_document_count() > 0:\n",
    "#     # Fetch the first document\n",
    "#     first_record = faculty_collection.find_one()\n",
    "#     print(\"First Record:\", first_record)\n",
    "# else:\n",
    "#     print(\"The 'departments' collection is empty or does not exist.\")\n",
    "\n",
    "# Load a text generation model (e.g., BART for summarization)\n",
    "#generator = pipeline(\"text-generation\", model=\"facebook/bart-large-cnn\")\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e937ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import spacy\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://Admin:Manager@cluster0.vths3.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "db = client[\"CollegeDB\"]\n",
    "faculty_collection = db[\"departments\"]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load a text generation model\n",
    "generator = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def fetch_faculty_info(name):\n",
    "    \"\"\"\n",
    "    Searches for a faculty member by name across all departments.\n",
    "    Uses fuzzy matching to handle variations in names.\n",
    "    \"\"\"\n",
    "    all_faculty = []\n",
    "\n",
    "    # Query to fetch only faculty names and their corresponding department details\n",
    "    all_departments = faculty_collection.find({}, {\"faculty\": 1, \"_id\": 0})\n",
    "\n",
    "    for department in all_departments:\n",
    "        all_faculty.extend(department.get(\"faculty\", []))\n",
    "\n",
    "    if not all_faculty:\n",
    "        return \"No faculty records found.\"\n",
    "\n",
    "    # Extract only the faculty names for fuzzy matching\n",
    "    faculty_names = {faculty[\"name\"]: faculty for faculty in all_faculty}\n",
    "    \n",
    "    # Find the closest match using fuzzy matching\n",
    "    best_match, best_score = process.extractOne(name, faculty_names.keys())\n",
    "\n",
    "    if best_score >= 50:  # Acceptable confidence threshold\n",
    "        return faculty_names[best_match]  # Return full faculty dictionary\n",
    "    \n",
    "    return \"Sorry, I couldn't find information on that faculty member.\"\n",
    "\n",
    "def generate_response(query):\n",
    "    \"\"\"\n",
    "    Understands the user query, extracts the faculty name, fetches information,\n",
    "    and converts it into a human-readable response.\n",
    "    \"\"\"\n",
    "    faculty_info = fetch_faculty_info(query)\n",
    "\n",
    "    if isinstance(faculty_info, str):  # If no faculty found\n",
    "        return faculty_info\n",
    "\n",
    "    structured_text = (\n",
    "        f\"Faculty Name: {faculty_info['name']}\\n\"\n",
    "        f\"Designation: {faculty_info['designation']}\\n\"\n",
    "        f\"Department: {faculty_info['department']}\\n\"\n",
    "        f\"Experience: {faculty_info['experience']} years\\n\"\n",
    "        f\"Email: {faculty_info['email']}\\n\"\n",
    "        f\"Research Areas: {', '.join(faculty_info.get('research_areas', []))}\\n\"\n",
    "        f\"Publications: {faculty_info['publications'].get('journals', 0)} Journals, \"\n",
    "        f\"{faculty_info['publications'].get('conferences', 0)} Conferences\\n\"\n",
    "        f\"Professional Memberships: {', '.join(faculty_info.get('professional_memberships', []))}\"\n",
    "    )\n",
    "\n",
    "    # Use NLP model for structured-to-natural conversion\n",
    "    prompt = (\n",
    "        f\"Convert the following structured faculty information into a human-like response:\\n\\n\"\n",
    "        f\"\\\"\\\"\\\"\\n{structured_text}\\n\\\"\\\"\\\"\\n\\n\"\n",
    "        f\"Generate a concise yet detailed response as a human would say.\"\n",
    "    )\n",
    "    \n",
    "    response = generator(prompt, max_length=129, min_length=50, do_sample=False)\n",
    "\n",
    "    return response[0]['summary_text'].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34f5ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a concise yet detailed response as a human would say. Convert the following structured faculty information into a human-like response. For example: Dr. K Devi Priya is an Associate Professor at Lakireddy Balireddy College of Engineering, Mylavaram.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example Usage\n",
    "print(generate_response(\"devi priya\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00479357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a concise yet detailed response as a human would say. Convert the following structured faculty information into a human-like response. For example: Dr. K Devi Priya is an Associate Professor at Lakireddy Balireddy College of Engineering, Mylavaram.\n",
      "Generate a concise yet detailed response as a human would say. Convert the following structured faculty information into a human-like response. For example: Dr. K Devi Priya is an Associate Professor at Lakireddy Balireddy College of Engineering, Mylavaram.\n",
      "Generate a concise yet detailed response as a human would say. Convert the following structured faculty information into a human-like response. For example: Dr. K Devi Priya is an Associate Professor at Lakireddy Balireddy College of Engineering, Mylavaram.\n",
      "Generate a concise yet detailed response as a human would say. Convert the following structured faculty information into a human-like response. For example: Dr. K Devi Priya is an Associate Professor at Lakireddy Balireddy College of Engineering, Mylavaram.\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(\"Who is Mrs. devi priya?\"))\n",
    "print(generate_response(\"Tell me about devi priya\"))\n",
    "print(generate_response(\"What are the research areas of devi priya?\"))\n",
    "print(generate_response(\"Can you provide info on devi priya?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3b7bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: Who is Shaik Salma Asiya Begum?\n",
      "Chatbot Response: Shaik Salma Asiya Begum is a professor of Computer Science and Engineering at the University of California, Berkeley. She is the author of the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"\n",
      "--------------------------------------------------\n",
      "User Query: Tell me about Mrs. Begum from CSE Department\n",
      "Chatbot Response: Sorry, I couldn't find the faculty member you're asking about.\n",
      "--------------------------------------------------\n",
      "User Query: I want details of Salma Asiya Begum\n",
      "Chatbot Response: Shaik Salma Asiya Begum is a professor of Computer Science and Engineering at the University of California, Berkeley. She is the author of the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"\n",
      "--------------------------------------------------\n",
      "User Query: Give me info on a professor named Shaik Salma Asiya Begum\n",
      "Chatbot Response: Shaik Salma Asiya Begum is a professor of Computer Science and Engineering at the University of California, Berkeley. She is the author of the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"Development of Machine Learning and Image Processing in Deep Learning\" and the book \"\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Who is Shaik Salma Asiya Begum?\",\n",
    "    \"Tell me about Mrs. Begum from CSE Department\",\n",
    "    \"I want details of Salma Asiya Begum\",\n",
    "    \"Give me info on a professor named Shaik Salma Asiya Begum\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(\"User Query:\", q)\n",
    "    print(\"Chatbot Response:\", generate_response(q))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f2afeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_faculty_info1(name):\n",
    "    all_departments = faculty_collection.find({}, {\"faculty\": 1})  # Fetch faculty members correctly\n",
    "    faculty_list = []\n",
    "\n",
    "    # Extract all faculty members from all departments\n",
    "    for department in all_departments:\n",
    "        for faculty in department.get(\"faculty\", []):\n",
    "            faculty_list.append(faculty)\n",
    "\n",
    "    # Debugging: Print extracted faculty names\n",
    "    if not faculty_list:\n",
    "        print(\"No faculty found in database.\")\n",
    "    \n",
    "    # Find the closest match using fuzzy matching\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for faculty in faculty_list:\n",
    "        faculty_name = faculty[\"name\"]\n",
    "        score = fuzz.ratio(name.strip().lower(), faculty_name.strip().lower())  # Calculate similarity\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = faculty\n",
    "\n",
    "    # Return if a good match (70% similarity) is found\n",
    "    if best_score >= 50:\n",
    "        return best_match\n",
    "    else:\n",
    "        return \"Sorry, I couldn't find information on that faculty member.\"\n",
    "\n",
    "def generate_response1(query):\n",
    "    faculty_info = fetch_faculty_info1(query)\n",
    "\n",
    "    if isinstance(faculty_info, str):  # If no faculty found\n",
    "        return faculty_info\n",
    "\n",
    "    formatted_info = (\n",
    "        f\"Name: {faculty_info['name']}\\n\"\n",
    "        f\"Designation: {faculty_info['designation']}\\n\"\n",
    "        f\"Department: {faculty_info['department']}\\n\"\n",
    "        f\"Experience: {faculty_info['experience']}\\n\"\n",
    "        f\"Email: {faculty_info['email']}\\n\"\n",
    "        f\"Research Areas: {', '.join(faculty_info['research_areas'])}\\n\"\n",
    "        f\"Publications: {faculty_info['publications']['journals']} Journals, \"\n",
    "        f\"{faculty_info['publications']['conferences']} Conferences\\n\"\n",
    "        f\"Professional Memberships: {', '.join(faculty_info['professional_memberships'])}\"\n",
    "    )\n",
    "\n",
    "    return formatted_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bb6740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Somala Jayaprada\n",
      "Designation: Professor and Head of THe Department\n",
      "Department: CSE(AI &ML)\n",
      "Experience: 20+ Years\n",
      "Email: drjayaprada@Lbrce.ac.in\n",
      "Research Areas: Data Analytics and Machine Learning\n",
      "Publications: 30 Journals, 14 Conferences\n",
      "Professional Memberships: CSI, ISTE, IAENG, ACM\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "query = \"Jayaprada\"\n",
    "print(generate_response1(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbba3531",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'model_validator' from 'pydantic' (D:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load environment variables\u001b[39;00m\n\u001b[0;32m      8\u001b[0m load_dotenv()\n",
      "File \u001b[1;32mD:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\langchain_huggingface\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     ChatHuggingFace,  \u001b[38;5;66;03m# type: ignore[import-not-found]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     HuggingFaceEmbeddings,\n\u001b[0;32m      6\u001b[0m     HuggingFaceEndpointEmbeddings,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     HuggingFaceEndpoint,\n\u001b[0;32m     10\u001b[0m     HuggingFacePipeline,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32mD:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\langchain_huggingface\\chat_models\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore[import-not-found]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     TGI_MESSAGE,\n\u001b[0;32m      3\u001b[0m     TGI_RESPONSE,\n\u001b[0;32m      4\u001b[0m     ChatHuggingFace,\n\u001b[0;32m      5\u001b[0m     _convert_message_to_chat_message,\n\u001b[0;32m      6\u001b[0m     _convert_TGI_message_to_LC_message,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatHuggingFace\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_convert_message_to_chat_message\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTGI_RESPONSE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m ]\n",
      "File \u001b[1;32mD:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:17\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     Any,\n\u001b[0;32m      6\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     cast,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     AsyncCallbackManagerForLLMRun,\n\u001b[0;32m     19\u001b[0m     CallbackManagerForLLMRun,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LanguageModelInput\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatModel\n",
      "File \u001b[1;32mD:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\langchain_core\\callbacks\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Callback handlers** allow listening to events in LangChain.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m**Class hierarchy:**\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    BaseCallbackHandler --> <name>CallbackHandler  # Example: AimCallbackHandler\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     AsyncCallbackHandler,\n\u001b[0;32m     12\u001b[0m     BaseCallbackHandler,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     ToolManagerMixin,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileCallbackHandler\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     AsyncCallbackManager,\n\u001b[0;32m     25\u001b[0m     AsyncCallbackManagerForChainGroup,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     dispatch_custom_event,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstdout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StdOutCallbackHandler\n",
      "File \u001b[1;32mD:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\langchain_core\\callbacks\\file.py:7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, TextIO, cast\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentAction, AgentFinish\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseCallbackHandler\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_text\n",
      "File \u001b[1;32mD:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\langchain_core\\agents.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Literal, Union\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserializable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Serializable\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     AIMessage,\n\u001b[0;32m     34\u001b[0m     BaseMessage,\n\u001b[0;32m     35\u001b[0m     FunctionMessage,\n\u001b[0;32m     36\u001b[0m     HumanMessage,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAgentAction\u001b[39;00m(Serializable):\n\u001b[0;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Represents a request to execute an action by an agent.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    The action consists of the name of the tool to execute and the input to pass\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    to the tool. The log is used to pass along extra information about the action.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\langchain_core\\messages\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Messages** are objects used in prompts and chat conversations.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m**Class hierarchy:**\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     AIMessage,\n\u001b[0;32m     20\u001b[0m     AIMessageChunk,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     BaseMessage,\n\u001b[0;32m     24\u001b[0m     BaseMessageChunk,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     messages_to_dict,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatMessage, ChatMessageChunk\n",
      "File \u001b[1;32mD:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\langchain_core\\messages\\ai.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Literal, Optional, Union, cast\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_validator\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotRequired, Self, TypedDict\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     BaseMessage,\n\u001b[0;32m     10\u001b[0m     BaseMessageChunk,\n\u001b[0;32m     11\u001b[0m     merge_content,\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'model_validator' from 'pydantic' (D:\\Users\\KISHORE NANDHAN\\anaconda3\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "from fuzzywuzzy import process\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://Admin:Manager@cluster0.vths3.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "db = client[\"CollegeDB\"]\n",
    "faculty_collection = db[\"departments\"]\n",
    "\n",
    "# Set up Hugging Face API\n",
    "HUGGINGFACE_API_KEY = \"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACE_API_KEY\n",
    "\n",
    "# Load the Mistral-7B model\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    task=\"text-generation\",\n",
    "    max_length=700,  # Allows detailed responses\n",
    "    temperature=0.7,\n",
    "    huggingfacehub_api_token=HUGGINGFACE_API_KEY\n",
    ")\n",
    "\n",
    "def fetch_faculty_info(name):\n",
    "    \"\"\"\n",
    "    Searches for a faculty member by name across all departments.\n",
    "    Uses fuzzy matching to handle variations in names.\n",
    "    \"\"\"\n",
    "    all_faculty = []\n",
    "\n",
    "    # Query to fetch only faculty names and their corresponding department details\n",
    "    all_departments = faculty_collection.find({}, {\"faculty\": 1, \"_id\": 0})\n",
    "\n",
    "    for department in all_departments:\n",
    "        all_faculty.extend(department.get(\"faculty\", []))\n",
    "\n",
    "    if not all_faculty:\n",
    "        return \"No faculty records found.\"\n",
    "\n",
    "    # Extract only the faculty names for fuzzy matching\n",
    "    faculty_names = {faculty[\"name\"]: faculty for faculty in all_faculty}\n",
    "    \n",
    "    # Find the closest match using fuzzy matching\n",
    "    best_match, best_score = process.extractOne(name, faculty_names.keys())\n",
    "\n",
    "    if best_score >= 50:  # Acceptable confidence threshold\n",
    "        return faculty_names[best_match]  # Return full faculty dictionary\n",
    "    \n",
    "    return \"Sorry, I couldn't find information on that faculty member.\"\n",
    "\n",
    "def generate_response(query):\n",
    "    \"\"\"\n",
    "    Understands the user query, extracts the faculty name, fetches information,\n",
    "    and converts it into a human-readable response.\n",
    "    \"\"\"\n",
    "    faculty_info = fetch_faculty_info(query)\n",
    "\n",
    "    if isinstance(faculty_info, str):  # If no faculty found\n",
    "        return faculty_info\n",
    "\n",
    "    structured_text = (\n",
    "        f\"Faculty Name: {faculty_info['name']}\\n\"\n",
    "        f\"Designation: {faculty_info['designation']}\\n\"\n",
    "        f\"Department: {faculty_info['department']}\\n\"\n",
    "        f\"Experience: {faculty_info['experience']} years\\n\"\n",
    "        f\"Email: {faculty_info['email']}\\n\"\n",
    "        f\"Research Areas: {', '.join(faculty_info.get('research_areas', []))}\\n\"\n",
    "        f\"Publications: {faculty_info['publications'].get('journals', 0)} Journals, \"\n",
    "        f\"{faculty_info['publications'].get('conferences', 0)} Conferences\\n\"\n",
    "        f\"Professional Memberships: {', '.join(faculty_info.get('professional_memberships', []))}\"\n",
    "    )\n",
    "\n",
    "    # Use Mistral-7B-Instruct for structured-to-natural conversion\n",
    "    prompt = (\n",
    "        f\"Convert the following structured faculty information into a human-like response:\\n\\n\"\n",
    "        f\"\\\"\\\"\\\"\\n{structured_text}\\n\\\"\\\"\\\"\\n\\n\"\n",
    "        f\"Generate a concise yet detailed response as a human would say.\"\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return response.strip()\n",
    "\n",
    "# Example usage\n",
    "print(generate_response(\"Dr. D. Veeraiah\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627f403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2268e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
